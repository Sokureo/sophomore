{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Fine, I don't think blocking is a solution to ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ter. v er.</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>.\\n\\nNeither am I. Pants suck. They should all...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>iYou're missing my point so badly, I can't tel...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>photo \\n\\ni'll see what i can do to it.  i've...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        comment_text  toxic  severe_toxic  \\\n",
       "0  Fine, I don't think blocking is a solution to ...      0             0   \n",
       "1                                         ter. v er.      1             0   \n",
       "2  .\\n\\nNeither am I. Pants suck. They should all...      1             0   \n",
       "3  iYou're missing my point so badly, I can't tel...      0             0   \n",
       "4   photo \\n\\ni'll see what i can do to it.  i've...      0             0   \n",
       "\n",
       "   obscene  threat  insult  identity_hate  \n",
       "0        0       0       0              0  \n",
       "1        1       0       1              0  \n",
       "2        1       0       0              0  \n",
       "3        0       0       0              0  \n",
       "4        0       0       0              0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('train.csv').fillna(' ')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id0</td>\n",
       "      <td>ok thanks can i request a new article under su...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id1</td>\n",
       "      <td>I deleted Bluesnews.com, which was a redirect ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id2</td>\n",
       "      <td>gYes, there is definite value in documenting t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id3</td>\n",
       "      <td>You STUPID ASSHOLES. You dont know anything!!!...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id4</td>\n",
       "      <td>,\"\\n\\nSearch my ass instead.  I read the corre...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id                                       comment_text\n",
       "0  id0  ok thanks can i request a new article under su...\n",
       "1  id1  I deleted Bluesnews.com, which was a redirect ...\n",
       "2  id2  gYes, there is definite value in documenting t...\n",
       "3  id3  You STUPID ASSHOLES. You dont know anything!!!...\n",
       "4  id4  ,\"\\n\\nSearch my ass instead.  I read the corre..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = pd.read_csv('test.csv').fillna(' ')\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = df['comment_text']\n",
    "X_test = df_test['comment_text']\n",
    "X = pd.concat([X_train, X_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "toxic = df[df['toxic'] == 1]['comment_text'].apply(lambda x: tokenize(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    comp = re.compile('[A-Za-z\\'\\-]+')\n",
    "    tokens = comp.findall(text.lower())\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "freq = nltk.FreqDist(word for sent in toxic.values for word in sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('hellx', 1),\n",
       " ('dolescum', 1),\n",
       " ('couse', 1),\n",
       " ('kinghy', 1),\n",
       " ('cordial', 1),\n",
       " ('downtrodden', 1),\n",
       " ('commoner', 1),\n",
       " ('wieght', 1),\n",
       " ('uniployed', 1),\n",
       " ('pogo', 1),\n",
       " ('modeled', 1),\n",
       " ('oa', 1),\n",
       " ('bartlett', 1),\n",
       " ('hocrriffic', 1),\n",
       " ('wiki-revenge', 1),\n",
       " ('vwar', 1),\n",
       " ('hottest', 1),\n",
       " ('farrakhanistic', 1),\n",
       " ('farrakhan', 1),\n",
       " ('cibao', 1),\n",
       " ('sammy', 1),\n",
       " ('sosa', 1),\n",
       " ('one-droppism', 1),\n",
       " ('hyperdecent', 1),\n",
       " ('dominicans', 1),\n",
       " ('cibae', 1),\n",
       " ('generalize', 1),\n",
       " ('nationlaity', 1),\n",
       " ('dominican', 1),\n",
       " ('intermarrired', 1),\n",
       " ('mulattoes', 1),\n",
       " ('bad-mouthing', 1),\n",
       " ('pea-sized', 1),\n",
       " ('neantherthals', 1),\n",
       " ('eloping', 1),\n",
       " ('rams', 1),\n",
       " ('mis-use', 1),\n",
       " ('scallywag', 1),\n",
       " ('iim', 1),\n",
       " ('eah', 1),\n",
       " ('clownx', 1),\n",
       " ('niggerkite', 1),\n",
       " ('oweeds', 1),\n",
       " ('bussines', 1),\n",
       " ('nanjing', 1),\n",
       " ('nazipedia', 1),\n",
       " ('explicity', 1),\n",
       " ('bodily', 1),\n",
       " ('satisfactory', 1),\n",
       " ('conflcit', 1),\n",
       " ('abuot', 1),\n",
       " ('inappropriateness', 1),\n",
       " ('michelle', 1),\n",
       " ('stpo', 1),\n",
       " ('probablay', 1),\n",
       " ('bareback', 1),\n",
       " ('rantings', 1),\n",
       " ('retort', 1),\n",
       " ('doorknob', 1),\n",
       " ('healing', 1),\n",
       " ('irude', 1),\n",
       " ('picket', 1),\n",
       " (\"'unionist\", 1),\n",
       " (\"trash'\", 1),\n",
       " (\"'subhuman\", 1),\n",
       " (\"garbage'\", 1),\n",
       " ('famousdog', 1),\n",
       " ('vehemently', 1),\n",
       " ('acupuncture', 1),\n",
       " ('endogenous', 1),\n",
       " ('kmk', 1),\n",
       " ('unrefrenced', 1),\n",
       " ('restler', 1),\n",
       " ('estler', 1),\n",
       " ('fills', 1),\n",
       " ('dl', 1),\n",
       " ('left-lib', 1),\n",
       " ('anti-se', 1),\n",
       " ('quisling', 1),\n",
       " ('urotrash', 1),\n",
       " ('vdumbledore', 1),\n",
       " ('uncovers', 1),\n",
       " ('dinna', 1),\n",
       " ('alpha', 1),\n",
       " ('omega', 1),\n",
       " ('innitn', 1),\n",
       " ('specialists', 1),\n",
       " (\"she'll\", 1),\n",
       " ('off-', 1),\n",
       " ('bernstein', 1),\n",
       " ('nstupido', 1),\n",
       " ('reverto', 1),\n",
       " ('hioo', 1),\n",
       " ('putaa', 1),\n",
       " ('midarme', 1),\n",
       " ('mdiarme', 1),\n",
       " ('nokay', 1),\n",
       " ('uninformative', 1),\n",
       " ('gayv', 1),\n",
       " ('relist', 1),\n",
       " ('snype', 1),\n",
       " ('truthfull', 1),\n",
       " ('vterrible', 1),\n",
       " ('web-link', 1),\n",
       " ('feedbags', 1),\n",
       " ('ecl', 1),\n",
       " ('dukejournals', 1),\n",
       " ('vol', 1),\n",
       " ('coolpage', 1),\n",
       " ('pianistl', 1),\n",
       " ('cusse', 1),\n",
       " ('tomko', 1),\n",
       " ('timko', 1),\n",
       " ('charms', 1),\n",
       " ('uhk', 1),\n",
       " ('wa', 1),\n",
       " ('constr', 1),\n",
       " ('opology', 1),\n",
       " ('rulen', 1),\n",
       " ('vyes', 1),\n",
       " ('coatrack', 1),\n",
       " ('melissa', 1),\n",
       " ('bean', 1),\n",
       " (\"morgenthaler's\", 1),\n",
       " (\"goethean's\", 1),\n",
       " ('rosakam', 1),\n",
       " ('disingenuous', 1),\n",
       " ('compartmentalized', 1),\n",
       " ('mis-information', 1),\n",
       " ('institutionalized', 1),\n",
       " ('wino', 1),\n",
       " ('roko', 1),\n",
       " ('rivaling', 1),\n",
       " ('bannana', 1),\n",
       " ('sixth', 1),\n",
       " ('figging', 1),\n",
       " ('realities', 1),\n",
       " ('foist', 1),\n",
       " ('ispeculate', 1),\n",
       " ('burgz', 1),\n",
       " ('netaji', 1),\n",
       " ('homesick', 1),\n",
       " ('bottem', 1),\n",
       " ('desacrate', 1),\n",
       " ('sancturay', 1),\n",
       " ('bloodsucker', 1),\n",
       " ('numbnut', 1),\n",
       " ('breached', 1),\n",
       " ('ompwn', 1),\n",
       " ('omfmnlol', 1),\n",
       " ('equations', 1),\n",
       " ('mols', 1),\n",
       " ('snaped', 1),\n",
       " ('mater', 1),\n",
       " ('attribution', 1),\n",
       " ('boil', 1),\n",
       " ('webcite', 1),\n",
       " ('sry', 1),\n",
       " ('retrodumb', 1),\n",
       " (\"trial's\", 1),\n",
       " ('blithely', 1),\n",
       " ('dolts', 1),\n",
       " ('infromation', 1),\n",
       " ('lactose', 1),\n",
       " (\"intolerance'\", 1),\n",
       " ('iresponsible', 1),\n",
       " ('catty', 1),\n",
       " ('vapid', 1),\n",
       " ('no-no', 1),\n",
       " ('rotf', 1),\n",
       " ('ade', 1),\n",
       " ('federation', 1),\n",
       " ('anti-bulgarian', 1),\n",
       " ('shitopedia', 1),\n",
       " ('brainwash', 1),\n",
       " ('neo-turkic', 1),\n",
       " ('bone-drone', 1),\n",
       " ('bearded', 1),\n",
       " ('mullahs', 1),\n",
       " ('nautical', 1),\n",
       " ('surveillance', 1),\n",
       " ('recon', 1),\n",
       " ('waters', 1),\n",
       " ('fauna', 1),\n",
       " ('facilities', 1),\n",
       " ('speculative', 1),\n",
       " ('antagonistic', 1),\n",
       " ('sensationalist', 1),\n",
       " ('sensationalism', 1),\n",
       " ('vzoe', 1),\n",
       " ('rears', 1),\n",
       " ('subspicies', 1),\n",
       " ('cockblockers', 1),\n",
       " ('spitefulness', 1),\n",
       " ('stimulating', 1),\n",
       " ('acquiring', 1),\n",
       " ('torin', 1),\n",
       " (\"ic'mon\", 1),\n",
       " ('sumamry', 1),\n",
       " ('stopv', 1),\n",
       " ('ipiece', 1),\n",
       " ('obipedia', 1),\n",
       " ('bipedia', 1),\n",
       " ('dicksi', 1),\n",
       " ('dhcp', 1),\n",
       " ('hgb', 1),\n",
       " ('regarde', 1),\n",
       " ('ooozing', 1),\n",
       " ('lava', 1),\n",
       " ('wagon', 1),\n",
       " (\"asn't\", 1),\n",
       " ('vleave', 1),\n",
       " ('gaaaaaaaaaaaaaaaaaaaaaaaaay', 1),\n",
       " ('gaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa',\n",
       "  1),\n",
       " ('quaking', 1),\n",
       " ('appauling', 1),\n",
       " ('scrupples', 1),\n",
       " ('consistant', 1),\n",
       " ('white-related', 1),\n",
       " ('zima', 1),\n",
       " ('ltnono', 1),\n",
       " ('ibingo', 1),\n",
       " ('scales', 1),\n",
       " ('tipped', 1),\n",
       " ('rugby-', 1),\n",
       " ('uni', 1),\n",
       " ('xv', 1),\n",
       " ('prop', 1),\n",
       " (\"'tommy\", 1),\n",
       " (\"moore'\", 1),\n",
       " ('hankering', 1),\n",
       " ('ass-sume', 1),\n",
       " ('rfucker', 1),\n",
       " ('stable', 1),\n",
       " ('rangers', 1),\n",
       " ('bramins', 1),\n",
       " ('igantic', 1),\n",
       " ('gof', 1),\n",
       " ('jewsx', 1),\n",
       " ('pritty', 1),\n",
       " ('anab', 1),\n",
       " ('ragad', 1),\n",
       " ('beckon', 1),\n",
       " ('rakon', 1),\n",
       " ('akmon', 1),\n",
       " ('binadas', 1),\n",
       " ('bvade', 1),\n",
       " ('akhed', 1),\n",
       " ('whenvdk', 1),\n",
       " ('yalllllitalic', 1),\n",
       " ('textsmall', 1),\n",
       " ('prickn', 1),\n",
       " ('porchcrop', 1),\n",
       " ('communicagte', 1),\n",
       " ('banno', 1),\n",
       " ('assuring', 1),\n",
       " ('donor', 1),\n",
       " ('deafness', 1),\n",
       " ('disadvantages', 1),\n",
       " ('relates', 1),\n",
       " ('blindness', 1),\n",
       " ('feezo', 1),\n",
       " ('ome', 1),\n",
       " ('panicking', 1),\n",
       " (\"''e''\", 1),\n",
       " ('gotye', 1),\n",
       " ('seperates', 1),\n",
       " ('adduce', 1),\n",
       " ('ill-thought-out', 1),\n",
       " ('integity', 1),\n",
       " ('perceptivity', 1),\n",
       " ('banal', 1),\n",
       " ('longtime', 1),\n",
       " ('uniqueness', 1),\n",
       " ('unmentioned', 1),\n",
       " ('rigorously', 1),\n",
       " ('foung', 1),\n",
       " ('anti-', 1),\n",
       " ('greaterserbian', 1),\n",
       " ('croat', 1),\n",
       " ('wortheless', 1),\n",
       " ('vyea', 1),\n",
       " ('redo', 1),\n",
       " ('nifht', 1),\n",
       " ('flatter', 1),\n",
       " ('patronised', 1),\n",
       " (\"'running\", 1),\n",
       " ('mommy-ish', 1),\n",
       " ('fetch', 1),\n",
       " ('rheumatism', 1),\n",
       " ('misfortunes', 1),\n",
       " ('whomsoever', 1),\n",
       " ('privelages', 1),\n",
       " ('smalls', 1),\n",
       " ('musicfreak', 1),\n",
       " ('crackerx', 1),\n",
       " ('ronaldo', 1),\n",
       " ('accuracte', 1),\n",
       " ('nople', 1),\n",
       " ('yoou', 1),\n",
       " ('plkese', 1),\n",
       " ('oldthew', 1),\n",
       " ('adick', 1),\n",
       " ('varjeiiiina', 1),\n",
       " ('heda', 1),\n",
       " ('jordan', 1),\n",
       " ('machocarioca', 1),\n",
       " ('underhanded', 1),\n",
       " ('machiavellian', 1),\n",
       " ('crabby', 1),\n",
       " ('regina', 1),\n",
       " ('blo', 1),\n",
       " ('blatd', 1),\n",
       " (\"'nooooo\", 1),\n",
       " ('esploded', 1),\n",
       " ('oonicurn', 1),\n",
       " ('heavens', 1),\n",
       " ('rapscallion', 1),\n",
       " ('apostate', 1),\n",
       " ('hedonist', 1),\n",
       " ('nazi-occultist', 1),\n",
       " ('worshipper', 1),\n",
       " ('lll', 1),\n",
       " ('unicurn', 1),\n",
       " ('afrer', 1),\n",
       " ('splode', 1),\n",
       " ('kiled', 1),\n",
       " ('emmigrate', 1),\n",
       " ('capisci', 1),\n",
       " ('emmigrated', 1),\n",
       " ('polskinarodowiec', 1),\n",
       " ('sandpaper', 1),\n",
       " (\"phoebe's\", 1),\n",
       " ('breastsn', 1),\n",
       " ('chinelo', 1),\n",
       " ('chekava', 1),\n",
       " ('appoling', 1),\n",
       " ('unclassy', 1),\n",
       " ('representitive', 1),\n",
       " ('resides', 1),\n",
       " ('sincir', 1),\n",
       " ('appology', 1),\n",
       " ('wi-fi', 1),\n",
       " ('overstepping', 1),\n",
       " ('clings', 1),\n",
       " ('blanket', 1),\n",
       " ('allie', 1),\n",
       " ('tyoux', 1),\n",
       " ('dickwads', 1),\n",
       " ('oopssorryguys', 1),\n",
       " ('m-theory', 1),\n",
       " ('agreees', 1),\n",
       " ('nfdny', 1),\n",
       " ('tarnished', 1),\n",
       " ('razy', 1),\n",
       " ('azy', 1),\n",
       " ('ilovegame', 1),\n",
       " ('isummerphd', 1),\n",
       " ('gyah', 1),\n",
       " (\"ne's\", 1),\n",
       " ('idid', 1),\n",
       " ('lampard', 1),\n",
       " ('thistypical', 1),\n",
       " ('wikinonsense', 1),\n",
       " ('origionally', 1),\n",
       " ('-foolishben', 1),\n",
       " ('uwm', 1),\n",
       " ('trra', 1),\n",
       " ('mikewazowski', 1),\n",
       " ('d-bag', 1),\n",
       " ('trembeling', 1),\n",
       " ('stumble', 1),\n",
       " ('discu', 1),\n",
       " ('uniunea', 1),\n",
       " ('maghiar', 1),\n",
       " ('din', 1),\n",
       " ('nia', 1),\n",
       " ('wikiquette', 1),\n",
       " ('vandetta', 1),\n",
       " ('colonist', 1),\n",
       " ('doubtful', 1),\n",
       " ('inanimate', 1),\n",
       " ('tomahawk', 1),\n",
       " ('twig', 1),\n",
       " ('narratives', 1),\n",
       " ('nthat', 1),\n",
       " ('ljudenscwein', 1),\n",
       " ('alarms', 1),\n",
       " ('unsuspecting', 1),\n",
       " ('papal', 1),\n",
       " ('diluded', 1),\n",
       " ('sixteenth', 1),\n",
       " ('xblocked', 1),\n",
       " ('latore', 1),\n",
       " ('pimped', 1),\n",
       " ('trannys', 1),\n",
       " ('break-ins', 1),\n",
       " ('moan', 1),\n",
       " ('chiks', 1),\n",
       " ('haggling', 1),\n",
       " ('trivialities', 1),\n",
       " ('mathsci', 1),\n",
       " ('tweaked', 1),\n",
       " ('redactions', 1),\n",
       " ('surgical', 1),\n",
       " ('affecting', 1),\n",
       " ('technofaye', 1),\n",
       " ('runneth', 1),\n",
       " (\"mathsci's\", 1),\n",
       " ('occam', 1),\n",
       " ('hand-waving', 1),\n",
       " ('toothless', 1),\n",
       " ('poo-poo', 1),\n",
       " ('ludwigs', 1),\n",
       " ('constantine', 1),\n",
       " ('substitional', 1),\n",
       " ('life-time-hell-sentence', 1),\n",
       " ('un-selfish', 1),\n",
       " ('malfunctioning', 1),\n",
       " ('genesis', 1),\n",
       " ('pennies', 1),\n",
       " ('cbs', 1),\n",
       " ('cherry-pick', 1),\n",
       " ('pre-existing', 1),\n",
       " ('faaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaace', 1),\n",
       " ('nonsese', 1),\n",
       " ('psychos', 1),\n",
       " ('countzero', 1),\n",
       " ('pompos', 1),\n",
       " ('rifles', 1),\n",
       " ('pencils', 1),\n",
       " ('outlawed', 1),\n",
       " ('ironald', 1),\n",
       " ('mannum', 1),\n",
       " ('posit', 1),\n",
       " ('nwill', 1),\n",
       " ('browsing', 1),\n",
       " ('disagreementviolations', 1),\n",
       " ('tenants', 1),\n",
       " (\"'frivolous'\", 1),\n",
       " ('stonei', 1),\n",
       " ('devisive', 1),\n",
       " (\"airplane's\", 1),\n",
       " ('nunh-huh', 1),\n",
       " (\"indonesian's\", 1),\n",
       " ('textitalic', 1),\n",
       " ('scheming', 1),\n",
       " ('wallet', 1),\n",
       " ('reaturn', 1),\n",
       " ('ciarai', 1),\n",
       " ('waabi', 1),\n",
       " ('deobandi', 1),\n",
       " ('siratal', 1),\n",
       " ('mustakeem', 1),\n",
       " ('breeders', 1),\n",
       " ('fcukin', 1),\n",
       " ('oeveryone', 1),\n",
       " ('obs', 1),\n",
       " ('gramgarhia', 1),\n",
       " ('virdi', 1),\n",
       " ('matharu', 1),\n",
       " ('hunjan', 1),\n",
       " ('babiesl', 1),\n",
       " ('bowlesx', 1),\n",
       " ('xtry', 1),\n",
       " ('fountains', 1),\n",
       " ('edisontechcenter', 1),\n",
       " ('researched', 1),\n",
       " ('vynci', 1),\n",
       " ('glenelg', 1),\n",
       " ('knowone', 1),\n",
       " ('oman', 1),\n",
       " ('aria', 1),\n",
       " ('elam', 1),\n",
       " ('vlouis', 1),\n",
       " ('proyect', 1),\n",
       " ('caricature', 1),\n",
       " ('sayerslle', 1),\n",
       " (\"'disruption\", 1),\n",
       " (\"only'\", 1),\n",
       " (\"'banter'\", 1),\n",
       " ('bil', 1),\n",
       " ('kralizec', 1),\n",
       " ('witless', 1),\n",
       " ('fatuous', 1),\n",
       " ('unwise', 1),\n",
       " ('ill-advised', 1),\n",
       " ('imprudent', 1),\n",
       " ('injudicious', 1),\n",
       " ('thoughtless', 1),\n",
       " ('heedless', 1),\n",
       " ('quis', 1),\n",
       " ('custodiet', 1),\n",
       " ('ipsos', 1),\n",
       " ('custodes', 1),\n",
       " ('offencen', 1),\n",
       " ('pictoral', 1),\n",
       " ('brown-eyed', 1),\n",
       " ('gnpov', 1),\n",
       " ('countrymen', 1),\n",
       " ('mimic', 1),\n",
       " ('compartment', 1),\n",
       " ('tolking', 1),\n",
       " ('merkava', 1),\n",
       " ('lwow', 1),\n",
       " ('namings', 1),\n",
       " ('beatty', 1),\n",
       " ('prises', 1),\n",
       " ('titssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssss',\n",
       "  1),\n",
       " ('phelps', 1),\n",
       " ('reprobate', 1),\n",
       " ('whoremongers', 1),\n",
       " ('satan-worshipper', 1),\n",
       " ('odpierdalcie', 1),\n",
       " ('sie', 1),\n",
       " ('jebani', 1),\n",
       " ('faszy', 1),\n",
       " ('ci', 1),\n",
       " ('polski', 1),\n",
       " ('duuur', 1),\n",
       " ('fckko', 1),\n",
       " ('trashing', 1),\n",
       " ('fckng', 1),\n",
       " (\"troll'''\", 1),\n",
       " ('veric', 1),\n",
       " (\"bragg's\", 1),\n",
       " ('presents', 1),\n",
       " ('surrealcoconut', 1),\n",
       " ('sanitation', 1),\n",
       " ('bitchezzzzzzzzzzzzzzzz', 1),\n",
       " ('everlast', 1),\n",
       " (\"everlast's\", 1),\n",
       " ('casteless', 1),\n",
       " ('dalits', 1),\n",
       " ('comeon', 1),\n",
       " ('manukarnika', 1),\n",
       " ('dumbie-brain-head', 1),\n",
       " ('mwahahahahahahahahahahahahahahahahahahahaha', 1),\n",
       " ('constelation', 1),\n",
       " ('easiest', 1),\n",
       " ('bswc', 1),\n",
       " ('shun', 1),\n",
       " ('shuuuuuuuuun', 1),\n",
       " ('shuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuun', 1),\n",
       " ('missy', 1),\n",
       " ('claptrap', 1),\n",
       " ('filll', 1),\n",
       " ('loosre', 1),\n",
       " ('derek', 1),\n",
       " ('xwow', 1),\n",
       " ('druggo', 1),\n",
       " ('owell', 1),\n",
       " ('regress', 1),\n",
       " ('barrister', 1),\n",
       " ('anagram', 1),\n",
       " ('jd', 1),\n",
       " (\"shan't\", 1),\n",
       " ('copter', 1),\n",
       " ('-craig', 1),\n",
       " ('astound', 1),\n",
       " ('oiled', 1),\n",
       " (\"'''this\", 1),\n",
       " ('vandels', 1),\n",
       " ('xpuking', 1),\n",
       " ('pre', 1),\n",
       " ('eleted', 1),\n",
       " ('saud', 1),\n",
       " ('-arabia', 1),\n",
       " ('scientifics', 1),\n",
       " ('graded', 1),\n",
       " ('debunker', 1),\n",
       " ('debunk', 1),\n",
       " ('sptimes', 1),\n",
       " ('floridian', 1),\n",
       " ('skepticism', 1),\n",
       " ('non-life', 1),\n",
       " ('talkng', 1),\n",
       " ('flummery', 1),\n",
       " ('enlist', 1),\n",
       " (\"'expert\", 1),\n",
       " ('scientifc', 1),\n",
       " ('pitious', 1),\n",
       " (\"'no\", 1),\n",
       " (\"high-school'\", 1),\n",
       " (\"'scietific'\", 1),\n",
       " (\"'non-scientific'\", 1),\n",
       " ('psychics', 1),\n",
       " ('fakers', 1),\n",
       " ('inferred', 1),\n",
       " ('lingayat', 1),\n",
       " ('reetards', 1),\n",
       " ('reeetards', 1),\n",
       " ('assalawalekum', 1),\n",
       " ('shafique', 1),\n",
       " ('narendra', 1),\n",
       " ('pign', 1),\n",
       " ('ockpuppets', 1),\n",
       " ('respons', 1),\n",
       " ('lowercase', 1),\n",
       " ('gimps', 1),\n",
       " (\"lhe's\", 1),\n",
       " ('fist-fucking', 1),\n",
       " ('nrotflmao', 1),\n",
       " ('criticised', 1),\n",
       " (\"trahs's\", 1),\n",
       " ('underling', 1),\n",
       " ('goains', 1),\n",
       " ('morrell', 1),\n",
       " ('gayyyyyyyyyyyyyyyyyyyyyy', 1),\n",
       " ('idiculous', 1),\n",
       " ('jeppiz', 1),\n",
       " (\"oarbitrator's\", 1),\n",
       " ('sirry', 1),\n",
       " ('slop', 1),\n",
       " ('spook', 1),\n",
       " ('barnyard', 1),\n",
       " ('rooster', 1),\n",
       " ('naacp', 1),\n",
       " ('ahold', 1),\n",
       " ('burrbssss', 1),\n",
       " ('probarbaly', 1),\n",
       " ('harmonica', 1),\n",
       " ('rhymeless', 1),\n",
       " ('riff', 1),\n",
       " ('slaking', 1),\n",
       " ('wikapidea', 1),\n",
       " ('nijas', 1),\n",
       " ('atement', 1),\n",
       " ('tement', 1),\n",
       " ('comedia', 1),\n",
       " ('writtenn', 1),\n",
       " ('kashmiris', 1),\n",
       " ('sub-section', 1),\n",
       " ('eveidence', 1),\n",
       " ('styrofoam', 1),\n",
       " ('gyall', 1),\n",
       " ('shampooith', 1),\n",
       " ('roar-ith', 1),\n",
       " ('wardrobe', 1),\n",
       " ('pilgrimage', 1),\n",
       " ('narnia', 1),\n",
       " ('screamo', 1),\n",
       " ('she-lion', 1),\n",
       " ('kayla', 1),\n",
       " ('barton', 1),\n",
       " ('sermons', 1),\n",
       " ('reeligions', 1),\n",
       " ('bostwick', 1),\n",
       " ('muslums', 1),\n",
       " ('couep', 1),\n",
       " ('likn', 1),\n",
       " ('telecommunications', 1),\n",
       " (\"little's\", 1),\n",
       " ('eastbound', 1),\n",
       " ('angers', 1),\n",
       " ('geniuses', 1),\n",
       " ('morgue', 1),\n",
       " ('oved', 1),\n",
       " ('foreve', 1),\n",
       " ('christains', 1),\n",
       " ('vehement', 1),\n",
       " ('prentious', 1),\n",
       " ('earings', 1),\n",
       " (\"'cos\", 1),\n",
       " ('disrespecting', 1),\n",
       " ('pagans', 1),\n",
       " ('backup', 1),\n",
       " ('ebola', 1),\n",
       " ('informational', 1),\n",
       " ('athetic', 1),\n",
       " ('thetic', 1),\n",
       " ('bhagat', 1),\n",
       " ('arya', 1),\n",
       " ('samajist', 1),\n",
       " ('chist', 1),\n",
       " ('nullifies', 1),\n",
       " ('ronpaul', 1),\n",
       " ('casino', 1),\n",
       " ('mujahedins', 1),\n",
       " ('ceric', 1),\n",
       " ('reis', 1),\n",
       " ('specielly', 1),\n",
       " ('comed', 1),\n",
       " ('croats', 1),\n",
       " ('moldavian', 1),\n",
       " ('dammned', 1),\n",
       " ('roumanian', 1),\n",
       " ('transformed', 1),\n",
       " ('upson', 1),\n",
       " ('stupidkorsentryl', 1),\n",
       " ('fainting', 1),\n",
       " ('maximally', 1),\n",
       " ('demeans', 1),\n",
       " ('coarsens', 1),\n",
       " ('discourteous', 1),\n",
       " ('egged', 1),\n",
       " ('tame', 1),\n",
       " ('posture', 1),\n",
       " ('tray', 1),\n",
       " ('ahahaha', 1),\n",
       " ('userquiddity', 1),\n",
       " ('fandalism', 1),\n",
       " ('substantially', 1),\n",
       " ('presentation', 1),\n",
       " ('bolshevism', 1),\n",
       " ('noun', 1),\n",
       " ('adjetive', 1),\n",
       " ('crackpots', 1),\n",
       " ('antisemites', 1),\n",
       " ('bolshivism', 1),\n",
       " ('draius', 1),\n",
       " ('deduced', 1),\n",
       " ('deduction', 1),\n",
       " ('dofficult', 1),\n",
       " ('suckpoper', 1),\n",
       " ('noetica', 1),\n",
       " ('pop-x', 1),\n",
       " ('onathan', 1),\n",
       " ('utu', 1),\n",
       " ('prosecuting', 1),\n",
       " ('incivilty', 1),\n",
       " ('redits', 1),\n",
       " ('prefectly', 1),\n",
       " ('staistic', 1),\n",
       " ('colussi', 1),\n",
       " ('friuend', 1),\n",
       " ('reforms', 1),\n",
       " ('descroiptions', 1),\n",
       " ('digraceful', 1),\n",
       " ('crticism', 1),\n",
       " ('criticied', 1),\n",
       " ('apologises', 1),\n",
       " (\"l'm\", 1),\n",
       " ('broughy', 1),\n",
       " ('jeffreyneave', 1),\n",
       " ('ndubz', 1),\n",
       " ('n-dubz', 1),\n",
       " ('oooga', 1),\n",
       " ('booga', 1),\n",
       " ('fuckweed', 1),\n",
       " ('ahem', 1),\n",
       " ('announcement', 1),\n",
       " ('xeworlebi', 1),\n",
       " ('heart-attack', 1),\n",
       " (\"dia's\", 1),\n",
       " (\"ia's\", 1),\n",
       " ('tolstoy', 1),\n",
       " ('kurtz', 1),\n",
       " ('dowsing', 1),\n",
       " ('spoons', 1),\n",
       " ('omitted', 1),\n",
       " ('mansions', 1),\n",
       " ('royces', 1),\n",
       " ('drains', 1),\n",
       " ('stupidg', 1),\n",
       " ('ironholds', 1),\n",
       " (\"ironholds'\", 1),\n",
       " ('exp', 1),\n",
       " ('arcangel', 1),\n",
       " ('anticipation', 1),\n",
       " ('treasurytag', 1),\n",
       " (\"tellers'\", 1),\n",
       " ('wands', 1),\n",
       " ('terds', 1),\n",
       " ('eteion', 1),\n",
       " ('teion', 1),\n",
       " ('tessa', 1),\n",
       " ('spaztik', 1),\n",
       " ('noodlez', 1),\n",
       " ('bothwell', 1),\n",
       " ('attendees', 1),\n",
       " ('securityerrata', 1),\n",
       " ('subjectiv', 1),\n",
       " ('lei', 1),\n",
       " ('crapping', 1),\n",
       " ('creap', 1),\n",
       " ('ripleman', 1),\n",
       " ('float', 1),\n",
       " ('desided', 1),\n",
       " ('biohazard', 1),\n",
       " ('upchuck', 1),\n",
       " ('conman-er', 1),\n",
       " ('implode', 1),\n",
       " ('selve', 1),\n",
       " ('shooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooowwwwwwwwwwwwwwwwwwwwwww',\n",
       "  1),\n",
       " ('convetion', 1),\n",
       " ('clerk', 1),\n",
       " ('bestseller', 1),\n",
       " (\"connor's\", 1),\n",
       " ('wto', 1),\n",
       " ('man-hunt', 1),\n",
       " ('binky', 1),\n",
       " ('nban', 1),\n",
       " ('coliseum', 1),\n",
       " ('mural', 1),\n",
       " ('mahmood', 1),\n",
       " ('ommon', 1),\n",
       " ('mmon', 1),\n",
       " ('californiaalibaba', 1),\n",
       " ('self-grandizing', 1),\n",
       " (\"connolly's\", 1),\n",
       " ('connolly', 1),\n",
       " ('myp', 1),\n",
       " ('awome', 1),\n",
       " ('rspw', 1),\n",
       " ('poster', 1),\n",
       " ('stinker', 1),\n",
       " ('chelski', 1),\n",
       " ('cobalt', 1),\n",
       " ('interior', 1),\n",
       " ('misortie', 1),\n",
       " ('backseat', 1),\n",
       " ('moderating', 1),\n",
       " ('alaive', 1),\n",
       " ('valison', 1),\n",
       " ('winking', 1),\n",
       " ('antiturkish', 1),\n",
       " ('bastion', 1),\n",
       " ('vandalizer', 1),\n",
       " ('battling', 1),\n",
       " ('jewbotts', 1),\n",
       " ('stupidv', 1),\n",
       " ('vsex', 1),\n",
       " ('aerospace', 1),\n",
       " ('cuny', 1),\n",
       " ('lankan', 1),\n",
       " ('uncloaked', 1),\n",
       " ('bespectacled', 1),\n",
       " ('d-w-e-e-b', 1),\n",
       " ('uneven', 1),\n",
       " ('tutsis', 1),\n",
       " ('rwanda', 1),\n",
       " ('bosniaks', 1),\n",
       " ('leftist-revisionist', 1),\n",
       " ('succeeding', 1),\n",
       " ('remotest', 1),\n",
       " (\"popper's\", 1),\n",
       " ('hohner', 1),\n",
       " ('lscjessey', 1),\n",
       " ('bailey', 1),\n",
       " (\"charmaine's\", 1),\n",
       " ('alivei', 1),\n",
       " ('ceranthor', 1),\n",
       " ('a-m-e-r-i-u-c-a-n', 1),\n",
       " ('almight', 1),\n",
       " ('saxifrage', 1),\n",
       " ('gobbling', 1),\n",
       " ('kunts', 1),\n",
       " ('phaggot', 1),\n",
       " ('nvr', 1),\n",
       " ('oduck', 1),\n",
       " ('star-spangled', 1),\n",
       " (\"banner'\", 1),\n",
       " ('germane', 1),\n",
       " ('upfront', 1),\n",
       " ('underlinked', 1),\n",
       " ('delink', 1),\n",
       " ('elitists', 1),\n",
       " ('gwould', 1),\n",
       " ('plzkthxi', 1),\n",
       " ('nniggers', 1),\n",
       " ('dows', 1),\n",
       " ('bol', 1),\n",
       " ('tif', 1),\n",
       " ('jut', 1),\n",
       " ('hereo', 1),\n",
       " ('pigfuckers', 1),\n",
       " ('battlestar', 1),\n",
       " ('dabomb', 1),\n",
       " ('jizzbomb', 1),\n",
       " ('ahed', 1),\n",
       " ('iamandrewrice', 1),\n",
       " ('mor', 1),\n",
       " ('homofobe', 1),\n",
       " (\"'sup\", 1),\n",
       " ('shor', 1),\n",
       " ('mayte', 1),\n",
       " ('mayt', 1),\n",
       " ('bf', 1),\n",
       " ('ryte', 1),\n",
       " (\"a'm\", 1),\n",
       " ('reconsider', 1),\n",
       " ('gains', 1),\n",
       " ('sophisticated', 1),\n",
       " ('warmongering', 1),\n",
       " ('anglo-serb', 1),\n",
       " ('shitskin', 1),\n",
       " ('shaka', 1),\n",
       " ('anonv', 1),\n",
       " ('tiptoey', 1),\n",
       " ('goeathean', 1),\n",
       " ('nutty', 1),\n",
       " ('wikpeidia', 1),\n",
       " ('respective', 1),\n",
       " ('boxl', 1),\n",
       " ('measuring', 1),\n",
       " ('xyeah', 1),\n",
       " ('outn', 1),\n",
       " ('muscle-homos', 1),\n",
       " ('hjave', 1),\n",
       " ('arte', 1),\n",
       " ('burger-', 1),\n",
       " ('seaking', 1),\n",
       " ('misogynists', 1),\n",
       " ('irreligious', 1),\n",
       " (\"bi's\", 1),\n",
       " ('otakus', 1),\n",
       " ('dakimakura-owning', 1),\n",
       " ('waifu-loving', 1),\n",
       " ('tiff', 1),\n",
       " (\"'chat'\", 1),\n",
       " ('recommendation', 1),\n",
       " ('howell', 1),\n",
       " ('springs', 1),\n",
       " ('erotica', 1),\n",
       " ('underaged', 1),\n",
       " ('stormfront', 1),\n",
       " (\"'evidence'\", 1),\n",
       " ('oxy', 1),\n",
       " ('revel', 1),\n",
       " ('annoyances', 1),\n",
       " ('lulcroomsizprivateschool', 1),\n",
       " ('conversing', 1),\n",
       " ('facebook-tier', 1),\n",
       " ('emoticon', 1),\n",
       " ('texted', 1),\n",
       " ('suspensions', 1),\n",
       " ('intendant', 1),\n",
       " ('sniffers', 1),\n",
       " ('lolrandom', 1),\n",
       " ('visibly', 1),\n",
       " ('shit-talk', 1),\n",
       " ('plebian', 1),\n",
       " ('leftover', 1),\n",
       " (\"bhadani's\", 1),\n",
       " (\"bhadva-ni's\", 1),\n",
       " ('gfag', 1),\n",
       " ('nimrod', 1),\n",
       " ('ahs', 1),\n",
       " ('fuckingl', 1),\n",
       " ('ord', 1),\n",
       " ('descisions', 1),\n",
       " ('ssn', 1),\n",
       " ('inquire', 1),\n",
       " ('rubric', 1),\n",
       " ('coercive', 1),\n",
       " ('scheme', 1),\n",
       " ('entailed', 1),\n",
       " ('individualists', 1),\n",
       " ('self-measured', 1),\n",
       " ('sample', 1),\n",
       " ('coolnurse', 1),\n",
       " ('discrepancies', 1),\n",
       " ('mind-bender', 1),\n",
       " ('contemplate', 1),\n",
       " ('kudos', 1),\n",
       " ('gyes', 1),\n",
       " ('payouts', 1),\n",
       " ('pharmaceutical', 1),\n",
       " ('scientifically', 1),\n",
       " ('colloidal', 1),\n",
       " ('occurring', 1),\n",
       " ('abundance', 1),\n",
       " ('pesticides', 1),\n",
       " ('fertilisers', 1),\n",
       " (\"'dangerous'\", 1),\n",
       " ('diverse', 1),\n",
       " ('yehaw', 1),\n",
       " ('dokie', 1),\n",
       " ('urg', 1),\n",
       " ('luce', 1),\n",
       " ('fsu', 1),\n",
       " ('ennui', 1),\n",
       " ('followups', 1),\n",
       " ('cookbook', 1),\n",
       " ('imbreed', 1),\n",
       " ('comon', 1),\n",
       " ('piggies', 1),\n",
       " ('ericv', 1),\n",
       " ('vivid', 1),\n",
       " ('winding', 1),\n",
       " ('radcliffe', 1),\n",
       " ('johns', 1),\n",
       " ('hopkins', 1),\n",
       " (\"linda's\", 1),\n",
       " ('mutt', 1),\n",
       " ('big-breasted', 1),\n",
       " ('bombshell', 1),\n",
       " ('triumvirate', 1),\n",
       " ('innocents', 1),\n",
       " (\"'almost\", 1),\n",
       " (\"there'\", 1),\n",
       " ('bloomer', 1),\n",
       " ('mound', 1),\n",
       " ('lurker', 1),\n",
       " ('fortunate', 1),\n",
       " (\"wouldn'd\", 1),\n",
       " ('ribs', 1),\n",
       " ('chimed', 1),\n",
       " ('pointedly', 1),\n",
       " ...]"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(freq.items(), key=lambda x: x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "freq2 = nltk.FreqDist(word for sent in X_test.apply(lambda x: tokenize(x)) for word in sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'safety',\n",
       " 'nb',\n",
       " 'sooooo',\n",
       " 'swartz',\n",
       " 'happiness',\n",
       " 'douchae',\n",
       " 'macamhlaidh',\n",
       " 'grossly',\n",
       " 'easily',\n",
       " 'clarify',\n",
       " 'path',\n",
       " 'criteria',\n",
       " 'grade',\n",
       " 'feminist',\n",
       " 'coren',\n",
       " 'wikip',\n",
       " 'hometown',\n",
       " 'winds',\n",
       " 'dalits',\n",
       " 'anthony',\n",
       " 'foad',\n",
       " \"misterwiki's\",\n",
       " 'association',\n",
       " 'importance',\n",
       " 'pun',\n",
       " 'redknecks',\n",
       " 'paintings',\n",
       " 'glass',\n",
       " \"gc's\",\n",
       " 'admin',\n",
       " 'btng',\n",
       " 'reproduced',\n",
       " 'looked',\n",
       " 'spare',\n",
       " 'voiced',\n",
       " 'version',\n",
       " 'industrial',\n",
       " 'gutted',\n",
       " 'standardized',\n",
       " 'query',\n",
       " 'fundamental',\n",
       " 'toes',\n",
       " 'gong',\n",
       " 'res',\n",
       " 'chalk',\n",
       " 'kicking',\n",
       " 'premature',\n",
       " 'rangers',\n",
       " 'kirk',\n",
       " 'poof',\n",
       " 'hezbollah',\n",
       " 'addictive',\n",
       " 'hijacking',\n",
       " 'handlers',\n",
       " 'nnot',\n",
       " 'fewest',\n",
       " 'guide',\n",
       " 'prostate',\n",
       " 'rub',\n",
       " 'uninvolved',\n",
       " 'tertiary',\n",
       " \"din't\",\n",
       " 'ull',\n",
       " 'cameroon',\n",
       " 'someones',\n",
       " 'mongrel',\n",
       " 'connotation',\n",
       " 'lobby',\n",
       " 'klux',\n",
       " 'lare',\n",
       " 'barack',\n",
       " 'texas',\n",
       " 'slag',\n",
       " 'glorious',\n",
       " 'sayerslle',\n",
       " 'acceptable',\n",
       " 'have',\n",
       " 'true',\n",
       " 'write-up',\n",
       " 'yuck',\n",
       " 'editwarring',\n",
       " 'cambridgebayweather',\n",
       " 'dissident',\n",
       " 'pimping',\n",
       " 'frisco',\n",
       " 'cured',\n",
       " 'excuse',\n",
       " 'argumentative',\n",
       " 'bolding',\n",
       " 'columbia',\n",
       " \"ted's\",\n",
       " 'currency',\n",
       " 'impressing',\n",
       " 'standard',\n",
       " 'balkan',\n",
       " 'nyour',\n",
       " 'propogate',\n",
       " 'goons',\n",
       " 'gare',\n",
       " 'extremely',\n",
       " 'belonged',\n",
       " 'piggy',\n",
       " 'egg',\n",
       " 'successful',\n",
       " 'men',\n",
       " 'attended',\n",
       " 'high',\n",
       " 'morons',\n",
       " 'wizard',\n",
       " 'youv',\n",
       " 'faint',\n",
       " 'soil',\n",
       " 'clarifying',\n",
       " \"frickin'\",\n",
       " 'cruz',\n",
       " 'officials',\n",
       " 'robbed',\n",
       " 'wikinazis',\n",
       " 'checks',\n",
       " 'tangible',\n",
       " 'carolina',\n",
       " 'marry',\n",
       " 'descendant',\n",
       " 'stitler',\n",
       " 'unit',\n",
       " 'jainism',\n",
       " 'earthers',\n",
       " 'nevertheless',\n",
       " 'restraint',\n",
       " 'lahiru',\n",
       " 'definately',\n",
       " \"c'est\",\n",
       " 'kid',\n",
       " 're-worded',\n",
       " \"dad's\",\n",
       " 'privileges',\n",
       " 'whales',\n",
       " 'upset',\n",
       " 'interview',\n",
       " 'dandy',\n",
       " 'chest',\n",
       " 'teacher',\n",
       " 'shitler',\n",
       " 'cody',\n",
       " 'pompous',\n",
       " 'whiff',\n",
       " 'twist',\n",
       " 'nswer',\n",
       " 'session',\n",
       " 'objecting',\n",
       " 'landing',\n",
       " 'nm',\n",
       " 'study',\n",
       " 'writes',\n",
       " 'prequel',\n",
       " 'propaganda',\n",
       " 'bin',\n",
       " 'libstar',\n",
       " 'backside',\n",
       " 'warriors',\n",
       " 'caricature',\n",
       " 'advise',\n",
       " 'offline',\n",
       " 'cked',\n",
       " 'sly',\n",
       " \"mercado's\",\n",
       " 'sworn',\n",
       " \"-the'fortyfive'\",\n",
       " 'every',\n",
       " 'wine',\n",
       " 'rotten',\n",
       " 'yopur',\n",
       " 'perpetrators',\n",
       " 'dope',\n",
       " 'affair',\n",
       " 'heap',\n",
       " 'ratings',\n",
       " 'fee',\n",
       " 'rhythm',\n",
       " 'eek',\n",
       " 'bed',\n",
       " 'assimilated',\n",
       " 'sikhs',\n",
       " 'watchlists',\n",
       " 'liberalism',\n",
       " 'dose',\n",
       " 'deadlock',\n",
       " 'wr',\n",
       " 'pronunciation',\n",
       " 'graemel',\n",
       " 'squirms',\n",
       " 'recliner',\n",
       " \"'delete'\",\n",
       " 'theorist',\n",
       " 'charged',\n",
       " 'vah',\n",
       " 'ual',\n",
       " 'girlfriend',\n",
       " 'punitively',\n",
       " 'hold',\n",
       " 'manipulating',\n",
       " 'gothic',\n",
       " 'owhy',\n",
       " 'contradict',\n",
       " 'newspapers',\n",
       " 'linguistics',\n",
       " 'pay',\n",
       " 'lecturing',\n",
       " 'prime',\n",
       " '-me',\n",
       " 'deliberately',\n",
       " 'apec',\n",
       " 'displaying',\n",
       " 'leftists',\n",
       " 'vandalize',\n",
       " 'traits',\n",
       " 'th',\n",
       " 'future',\n",
       " 'fagit',\n",
       " 'harms',\n",
       " 'healthy',\n",
       " 'brandon',\n",
       " 'wikihow',\n",
       " 'ahem',\n",
       " 'bitter',\n",
       " 'cancel',\n",
       " 'call',\n",
       " 'chatting',\n",
       " 'return',\n",
       " 'mathematician',\n",
       " 'sealed',\n",
       " 'grander',\n",
       " 'high-ranking',\n",
       " 'policies',\n",
       " 'dahn',\n",
       " 'lair',\n",
       " 'gotta',\n",
       " 'enigmaman',\n",
       " 'made',\n",
       " 'bullcrap',\n",
       " 'waisting',\n",
       " 'wwe',\n",
       " 'threat',\n",
       " 'crushing',\n",
       " 'housewives',\n",
       " 'reword',\n",
       " 'assl',\n",
       " 'addendum',\n",
       " 'oimage',\n",
       " 'drop',\n",
       " 'feeling',\n",
       " 'covert',\n",
       " 'platform',\n",
       " 'ghost',\n",
       " 'journals',\n",
       " 'kitty',\n",
       " 'see',\n",
       " 'benoit',\n",
       " 'rachel',\n",
       " 'gardens',\n",
       " 'dwarfs',\n",
       " 'crosses',\n",
       " 'smh',\n",
       " \"users'\",\n",
       " \"jesus's\",\n",
       " 'xhey',\n",
       " 'me',\n",
       " 'knotted',\n",
       " 'standing',\n",
       " 'foreigners',\n",
       " 'lent',\n",
       " 'suppression',\n",
       " 'snivelling',\n",
       " 'hotmail',\n",
       " 'goverment',\n",
       " 'blog',\n",
       " 'repeats',\n",
       " 'dinners',\n",
       " 'yeah',\n",
       " 'occured',\n",
       " 'minors',\n",
       " 'thereby',\n",
       " 'capacity',\n",
       " 'giving',\n",
       " 'isa',\n",
       " 'foreeevvver',\n",
       " 'sake',\n",
       " 'ists',\n",
       " 'charles',\n",
       " 'artistic',\n",
       " 'deals',\n",
       " 'banhammer',\n",
       " 'village',\n",
       " 'preferred',\n",
       " 'phallus',\n",
       " 'tagging',\n",
       " 'lso',\n",
       " 'adolescent',\n",
       " 'uncles',\n",
       " 'ting',\n",
       " 'piling',\n",
       " 'mins',\n",
       " 'messes',\n",
       " 'unhappy',\n",
       " 'arsch',\n",
       " 'xenophobia',\n",
       " 'lu',\n",
       " 'confess',\n",
       " 'salary',\n",
       " 'matthew',\n",
       " 'patents',\n",
       " 'regan',\n",
       " 'principle',\n",
       " 'ended',\n",
       " 'roommates',\n",
       " \"jack's\",\n",
       " 'zuckerberg',\n",
       " 'bulgarians',\n",
       " 'therapy',\n",
       " 'mature',\n",
       " 'ishut',\n",
       " 'insulted',\n",
       " 'sex-positive',\n",
       " 'unification',\n",
       " 'andhra',\n",
       " 'guidelines',\n",
       " 'projecto-screen',\n",
       " 'merry',\n",
       " 'oil',\n",
       " 'cockup',\n",
       " 'cul',\n",
       " 'becomes',\n",
       " 'fill',\n",
       " 'competent',\n",
       " 'move',\n",
       " 'rumour',\n",
       " 'vindicated',\n",
       " 'albert',\n",
       " 'sucksi',\n",
       " 'drafted',\n",
       " 'murderer',\n",
       " 'fc',\n",
       " 'note',\n",
       " \"don't\",\n",
       " 'rams',\n",
       " 'practical',\n",
       " 'pal',\n",
       " 'metaphorically',\n",
       " 'trusted',\n",
       " 'wield',\n",
       " 'bicycle',\n",
       " 'consideration',\n",
       " 'separation',\n",
       " 'accepts',\n",
       " 'yadavs',\n",
       " 'collegiate',\n",
       " 'liable',\n",
       " 'monologues',\n",
       " 'directing',\n",
       " 'drinker',\n",
       " 'moronhi',\n",
       " 'dai',\n",
       " 'reminded',\n",
       " 'likewise',\n",
       " 'spending',\n",
       " 'syria',\n",
       " 'philosophy',\n",
       " 'armenia',\n",
       " 'pouring',\n",
       " 'participation',\n",
       " 'syphilis',\n",
       " 'handouts',\n",
       " 'pelmet',\n",
       " 'fuckface',\n",
       " 'nanjing',\n",
       " \"you's\",\n",
       " 'jealousy',\n",
       " 'emperor',\n",
       " 'depriving',\n",
       " 'plea',\n",
       " 'gets',\n",
       " 'presidency',\n",
       " 'prostitute',\n",
       " 'caught',\n",
       " 'cia',\n",
       " 'cocksucking',\n",
       " 'political',\n",
       " 'stephanie',\n",
       " 'ebusiness',\n",
       " 'tasting',\n",
       " 'hedonism',\n",
       " 'toilet',\n",
       " 'negative',\n",
       " 'innacurate',\n",
       " 'fellates',\n",
       " 'serer',\n",
       " 'gently',\n",
       " 'accidental',\n",
       " 'approx',\n",
       " 'lead',\n",
       " 'sufficient',\n",
       " 'rogue',\n",
       " 'theatre',\n",
       " 'nobel',\n",
       " 'rare',\n",
       " 'meyer',\n",
       " 'subordinate',\n",
       " \"people'\",\n",
       " 'intolerance',\n",
       " 'comprehension',\n",
       " 'central',\n",
       " 'today',\n",
       " 'fk',\n",
       " 'phase',\n",
       " 'enjoyment',\n",
       " 'rome',\n",
       " 'tunisia',\n",
       " 'assholel',\n",
       " 'implies',\n",
       " 'alabama',\n",
       " 'exploded',\n",
       " 'thomson',\n",
       " 'binky',\n",
       " 'molest',\n",
       " 'bum',\n",
       " 'appease',\n",
       " 'hows',\n",
       " \"american's\",\n",
       " 'ked',\n",
       " 'openly',\n",
       " 'rvv',\n",
       " 'yolo',\n",
       " 'ejaculate',\n",
       " 'ensuring',\n",
       " 'down',\n",
       " 'pain',\n",
       " 'maintenance',\n",
       " 'thwarted',\n",
       " 'invasion',\n",
       " 'vocals',\n",
       " 'influence',\n",
       " 'shhh',\n",
       " 'blade',\n",
       " 'addiction',\n",
       " 'interesting',\n",
       " 'reopen',\n",
       " 'jennifer',\n",
       " 'mugs',\n",
       " 'colonization',\n",
       " 'oldest',\n",
       " 'prejudice',\n",
       " 'thinks',\n",
       " 'beckon',\n",
       " 'sitush',\n",
       " 'sse',\n",
       " 'tryna',\n",
       " 'steamed',\n",
       " 'dealings',\n",
       " 'biographies',\n",
       " 'continuously',\n",
       " 'truce',\n",
       " 'beneath',\n",
       " 'balony',\n",
       " 'harrington',\n",
       " 'button',\n",
       " 'trademark',\n",
       " 'oshut',\n",
       " 'danny',\n",
       " 'w',\n",
       " 'hopes',\n",
       " 'tucky',\n",
       " 'woke',\n",
       " 'neva',\n",
       " 'isotope',\n",
       " 'millions',\n",
       " 'particle',\n",
       " 'existed',\n",
       " 'stalking',\n",
       " 'aunt',\n",
       " 'pounding',\n",
       " 'zzuuzz',\n",
       " 'pests',\n",
       " 'hare',\n",
       " 'inadvertently',\n",
       " 'tears',\n",
       " 'weep',\n",
       " 'goe',\n",
       " 'ives',\n",
       " 'cocks',\n",
       " 'brings',\n",
       " 'typos',\n",
       " 'complaints',\n",
       " 'jolie',\n",
       " 'lyoko',\n",
       " 'gall',\n",
       " 'significantly',\n",
       " 'lshut',\n",
       " 'ethnics',\n",
       " 'champs',\n",
       " 'company',\n",
       " 'visiting',\n",
       " 'peters',\n",
       " 'croats',\n",
       " 'surrender',\n",
       " 'advices',\n",
       " 'refocus',\n",
       " 'wikipeida',\n",
       " 'somone',\n",
       " 'urinate',\n",
       " 'van',\n",
       " 'wedding',\n",
       " 'drawings',\n",
       " 'fate',\n",
       " 'cherokee',\n",
       " 'anti-jewish',\n",
       " 'painful',\n",
       " \"ova's\",\n",
       " 'mat',\n",
       " 'card',\n",
       " 'mica',\n",
       " 'fights',\n",
       " 'rry',\n",
       " 'conference',\n",
       " 'trying',\n",
       " 'hehe',\n",
       " 'unproductive',\n",
       " 'genetic',\n",
       " 'fowler',\n",
       " 'unsigned',\n",
       " 'muck',\n",
       " 'refugee',\n",
       " 'no-life',\n",
       " 'mother-assad',\n",
       " 'c-unt',\n",
       " 'trunk',\n",
       " 'america',\n",
       " 'thumbs',\n",
       " 'best',\n",
       " 'garden',\n",
       " 'unpleasant',\n",
       " 'discriminatory',\n",
       " 'santin',\n",
       " 'bloat',\n",
       " \"'t\",\n",
       " 'ukrainian',\n",
       " 'keeps',\n",
       " 'amarth',\n",
       " \"somebody's\",\n",
       " 'beetch',\n",
       " 'bisexual',\n",
       " 'garrison',\n",
       " 'subjective',\n",
       " 'vulgar',\n",
       " 'baddest',\n",
       " 'aphorism',\n",
       " 'scratch',\n",
       " 'pension',\n",
       " 'object',\n",
       " 'tourism',\n",
       " 'ix',\n",
       " 'warming',\n",
       " 'corner',\n",
       " 'migrated',\n",
       " 'vain',\n",
       " 'repressed',\n",
       " 'brendan',\n",
       " 'degrade',\n",
       " \"should've\",\n",
       " 'traded',\n",
       " 'examined',\n",
       " 'incapacitated',\n",
       " 'fucky',\n",
       " 'spell',\n",
       " 'hero',\n",
       " 'sensitive',\n",
       " 'offering',\n",
       " 'calling',\n",
       " 'surf',\n",
       " 'beck',\n",
       " 'genocidal',\n",
       " 'melvin',\n",
       " 'deeds',\n",
       " 'employee',\n",
       " 'mercury',\n",
       " 'niggas',\n",
       " 'cupboard',\n",
       " 'watched',\n",
       " 'egotistical',\n",
       " 'wretch',\n",
       " 'appreciation',\n",
       " 'suspended',\n",
       " 'ad',\n",
       " 'mariah',\n",
       " 'grip',\n",
       " 'captain-poison',\n",
       " 'guesses',\n",
       " 'itself',\n",
       " 'lowest',\n",
       " 'buggy',\n",
       " 'fucki',\n",
       " \"motherfuckin'\",\n",
       " 'domestic',\n",
       " 'princes',\n",
       " 'revolving',\n",
       " 'develop',\n",
       " 'editting',\n",
       " 'fanboys',\n",
       " 'bell',\n",
       " 'puppy',\n",
       " 'chaaaaa',\n",
       " 'inda',\n",
       " 'legit',\n",
       " 'kinu',\n",
       " 'xd',\n",
       " 'measuring',\n",
       " 'travels',\n",
       " 'fortune',\n",
       " 'xthat',\n",
       " 'magnetism',\n",
       " 'seized',\n",
       " 'verify',\n",
       " 'damn',\n",
       " 'admitted',\n",
       " 'xhe',\n",
       " 'specific',\n",
       " 'bury',\n",
       " 'hasspoken',\n",
       " 'feet',\n",
       " 'substantial',\n",
       " 'inverse',\n",
       " 'accomplished',\n",
       " 'bloodthirsty',\n",
       " 'cared',\n",
       " 'win',\n",
       " 'oink',\n",
       " 'slap',\n",
       " 'prince',\n",
       " 'lane',\n",
       " 'russians',\n",
       " 'sean',\n",
       " 'clients',\n",
       " \"that'll\",\n",
       " 'xok',\n",
       " 'existance',\n",
       " 'pinola',\n",
       " 'retard-',\n",
       " 'generations',\n",
       " 'queen',\n",
       " 'launch',\n",
       " 'amuse',\n",
       " 'probe',\n",
       " 'calvin',\n",
       " 'wade',\n",
       " 'worried',\n",
       " 'son',\n",
       " 'benefits',\n",
       " 'february',\n",
       " 'mean',\n",
       " 'overo',\n",
       " 'humour',\n",
       " 'farcical',\n",
       " 'permantly',\n",
       " 'condone',\n",
       " 'pie',\n",
       " 'mysterious',\n",
       " 'regular',\n",
       " 'ni',\n",
       " 'elementary',\n",
       " 'pagan',\n",
       " 'gland',\n",
       " 'unemployeed',\n",
       " 'discerned',\n",
       " 'food',\n",
       " 'android',\n",
       " 'beard',\n",
       " 'election',\n",
       " 'sprang',\n",
       " 'cooperation',\n",
       " 'contained',\n",
       " 'trivialities',\n",
       " 'seeming',\n",
       " 'yankee',\n",
       " 'jam',\n",
       " 'obscure',\n",
       " 'moderating',\n",
       " 'copying',\n",
       " 'medals',\n",
       " 'towards',\n",
       " 'well-written',\n",
       " 'although',\n",
       " 'billions',\n",
       " 'restore',\n",
       " 'imagine',\n",
       " 'raul',\n",
       " 'contract',\n",
       " 'woo',\n",
       " 'suicide',\n",
       " 'mixture',\n",
       " 'we',\n",
       " 'imagined',\n",
       " 'date',\n",
       " 'advocate',\n",
       " 'amoebas',\n",
       " 'shit',\n",
       " 'household',\n",
       " 'censored',\n",
       " 'chat',\n",
       " 'latchkey',\n",
       " 'pilate',\n",
       " 'newbies',\n",
       " 'shrinking',\n",
       " 'synonym',\n",
       " 'obsessive-compulsive',\n",
       " 'adds',\n",
       " 'stick',\n",
       " 'capture',\n",
       " 'marked',\n",
       " 'font-size',\n",
       " 'spider',\n",
       " 'zuck',\n",
       " 'come',\n",
       " 'fired',\n",
       " 'spoofs',\n",
       " 'semiticism',\n",
       " 'dresden',\n",
       " 'kool',\n",
       " 'obviously',\n",
       " \"people's\",\n",
       " 'xxxx',\n",
       " 'eddie',\n",
       " 'tate',\n",
       " 'entities',\n",
       " 'floating',\n",
       " 'jerked',\n",
       " 'kawwww-kawwww',\n",
       " 'concensus',\n",
       " 'towns',\n",
       " 'architect',\n",
       " 'charges',\n",
       " 'providers',\n",
       " 'satanic',\n",
       " 'deletionists',\n",
       " 'so-and-so',\n",
       " 'gsuck',\n",
       " 'target',\n",
       " 'per',\n",
       " 'avery',\n",
       " 'moreover',\n",
       " 'similar',\n",
       " 'sorry',\n",
       " 'mongoloid',\n",
       " 'negligent',\n",
       " 'nicolas',\n",
       " 'ostop',\n",
       " 'spring',\n",
       " 'adjustments',\n",
       " 'warn',\n",
       " 'profanities',\n",
       " 'programme',\n",
       " 'modify',\n",
       " 'excessively',\n",
       " 'implied',\n",
       " 'voyeurism',\n",
       " 'ps',\n",
       " 'hes',\n",
       " 'deciding',\n",
       " 'reeves',\n",
       " 'politely',\n",
       " 'deletions',\n",
       " 'spent',\n",
       " 'lemonade',\n",
       " 'vous',\n",
       " 'scout',\n",
       " 'interference',\n",
       " 'exhibit',\n",
       " 'thrives',\n",
       " 'explicitly',\n",
       " 'thanks',\n",
       " 'salute',\n",
       " 'burgers',\n",
       " 'urs',\n",
       " 'wifi',\n",
       " 'jean',\n",
       " 'tna',\n",
       " 'dressing',\n",
       " 'mista',\n",
       " 'derhexer',\n",
       " 'ronaldo',\n",
       " 'hater',\n",
       " 'elieve',\n",
       " 'bryte',\n",
       " 'neiln',\n",
       " 'palestine',\n",
       " 'connolly',\n",
       " 'operations',\n",
       " 'potter',\n",
       " 'begging',\n",
       " 'stomping',\n",
       " 'chronology',\n",
       " 'dry',\n",
       " 'disrespect',\n",
       " 'meaningful',\n",
       " 'spot',\n",
       " 'osi',\n",
       " 'ranking',\n",
       " 'appearing',\n",
       " 'vert',\n",
       " 'ensued',\n",
       " 'fenian',\n",
       " 'window',\n",
       " 'seemingly',\n",
       " 'friendless',\n",
       " 'benedict',\n",
       " 'welfare',\n",
       " 'keys',\n",
       " 'spit',\n",
       " 'firefox',\n",
       " 'kurdistan',\n",
       " 'chess',\n",
       " 'permanent',\n",
       " 'ultra-nationalism',\n",
       " 'uncyc',\n",
       " 'retiring',\n",
       " 'puke',\n",
       " 'sixth',\n",
       " 'jake',\n",
       " 'conflicting',\n",
       " 'hu',\n",
       " 'affairs',\n",
       " 'copyrights',\n",
       " 'multitude',\n",
       " 'milburn',\n",
       " 'jesse',\n",
       " 'chicken',\n",
       " 'wrestle',\n",
       " 'helen',\n",
       " 'bossy',\n",
       " 'riders',\n",
       " 'inevitable',\n",
       " 'laurent',\n",
       " 'tons',\n",
       " 'prussian',\n",
       " 'yourselves',\n",
       " 'rival',\n",
       " 'canon',\n",
       " 'clarified',\n",
       " 'kat',\n",
       " 'ki',\n",
       " 'action',\n",
       " 'offenses',\n",
       " 'jewish',\n",
       " 'youtube',\n",
       " 'blessed',\n",
       " 'ideas',\n",
       " 'cites',\n",
       " 'lots',\n",
       " 'assn',\n",
       " 'infest',\n",
       " 'liar',\n",
       " 'packs',\n",
       " 'nscrew',\n",
       " 'turkic',\n",
       " 'sd',\n",
       " 'v',\n",
       " 'attention',\n",
       " 'part',\n",
       " 'ligitimate',\n",
       " 'raza',\n",
       " 'swalwell',\n",
       " 'huggle',\n",
       " 'suspected',\n",
       " 'anti-censorship',\n",
       " 'blush',\n",
       " 'stranger',\n",
       " 'stealing',\n",
       " 'f-',\n",
       " 'letter',\n",
       " 'cool-down',\n",
       " 'owed',\n",
       " 'tbhotch',\n",
       " 'germany',\n",
       " 'chicks',\n",
       " 'nigel',\n",
       " 'dakota',\n",
       " 'orton',\n",
       " 'addition',\n",
       " 'thrusting',\n",
       " 'nyer',\n",
       " 'wars',\n",
       " 'innocents',\n",
       " 'bytch',\n",
       " 'printing',\n",
       " 'gentleman',\n",
       " 'grapes',\n",
       " 'skeptic',\n",
       " 'dynasty',\n",
       " 'dub',\n",
       " 'fukcing',\n",
       " 'finger',\n",
       " 'deception',\n",
       " 'behavioral',\n",
       " 'hidden',\n",
       " 'metro',\n",
       " 'waz',\n",
       " 'conversion',\n",
       " 'mani',\n",
       " 'periodically',\n",
       " 'vi',\n",
       " 'stupids',\n",
       " 'helpme',\n",
       " 'kit',\n",
       " 'afterwards',\n",
       " 'otl',\n",
       " 'scapegoat',\n",
       " 'pbs',\n",
       " 'norris',\n",
       " 'poll',\n",
       " 'inferences',\n",
       " 'emotions',\n",
       " 'responsibly',\n",
       " 'dosnt',\n",
       " 'bowels',\n",
       " 'philippine',\n",
       " 'tv',\n",
       " 'door',\n",
       " 'trample',\n",
       " 'losers',\n",
       " 'cracka',\n",
       " 'loony',\n",
       " 'circumstance',\n",
       " 'marc',\n",
       " 'lbs',\n",
       " 'prey',\n",
       " 'jockey',\n",
       " 'history',\n",
       " 'consists',\n",
       " 'hungarian',\n",
       " 'tut',\n",
       " 'nableezy',\n",
       " 'credit',\n",
       " 'noticed',\n",
       " 'conniving',\n",
       " 'fortune-teller',\n",
       " 'abb',\n",
       " 'sets',\n",
       " 'ovember',\n",
       " 'userpages',\n",
       " 'imposter',\n",
       " 'deaths',\n",
       " 'bullied',\n",
       " 'akerans',\n",
       " 'anonymous',\n",
       " 'peek',\n",
       " 'detroit',\n",
       " 'carefully',\n",
       " 'studied',\n",
       " 'ator',\n",
       " 'driving',\n",
       " 'tirade',\n",
       " 'summary',\n",
       " 'pdf',\n",
       " 'bod',\n",
       " 'lately',\n",
       " 'our',\n",
       " 'bothwell',\n",
       " 'created',\n",
       " 'screens',\n",
       " 'lolx',\n",
       " 'also',\n",
       " 'lei',\n",
       " 'composer',\n",
       " 'profs',\n",
       " 'greetings',\n",
       " 'vancouver',\n",
       " 'viruses',\n",
       " 'based',\n",
       " 'tosh',\n",
       " 'cooley',\n",
       " 'bieber',\n",
       " 'directly',\n",
       " 'both',\n",
       " 'alasdair',\n",
       " 'vision',\n",
       " 'texts',\n",
       " 'bailey',\n",
       " 'rite',\n",
       " 'fa',\n",
       " 'helped',\n",
       " 'nosey',\n",
       " 'college',\n",
       " 'embassy',\n",
       " 'built',\n",
       " 'teabag',\n",
       " 'trucks',\n",
       " 'peopel',\n",
       " 'refugees',\n",
       " 'fog',\n",
       " 'supply',\n",
       " 'patronizing',\n",
       " 'responsibilities',\n",
       " ...}"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq.keys() & freq2.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Fine, I don't think blocking is a solution to ...\n",
       "1                                           ter. v er.\n",
       "2    .\\n\\nNeither am I. Pants suck. They should all...\n",
       "3    iYou're missing my point so badly, I can't tel...\n",
       "4     photo \\n\\ni'll see what i can do to it.  i've...\n",
       "Name: comment_text, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.preprocessing import Normalizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.sparse import hstack\n",
    "import numpy as np\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word_vectorizer = TfidfVectorizer(\n",
    "    sublinear_tf=True,\n",
    "    strip_accents='unicode',\n",
    "    analyzer='word',\n",
    "    token_pattern=r'\\w{4,}',\n",
    "    stop_words='english',\n",
    "    ngram_range=(1, 1),\n",
    "    max_features=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word_vectorizer.fit(X)\n",
    "X_train_word = word_vectorizer.transform(X_train)\n",
    "X_test_word = word_vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "terms = word_vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# show topic descriptors\n",
    "def get_descriptor( terms, H, topic_index, top ):\n",
    "    top_indices = np.argsort( H[topic_index,:] )[::-1]\n",
    "    top_terms = []\n",
    "    for term_index in top_indices[0:top]:\n",
    "        top_terms.append( terms[term_index] )\n",
    "    return top_terms\n",
    "\n",
    "def get_all_descriptors(k, H, terms, top):\n",
    "    key_words = []\n",
    "    for topic_index in range(k):\n",
    "        descriptor = get_descriptor( terms, H, topic_index, top )\n",
    "        key_words.append(descriptor)\n",
    "        str_descriptor = \", \".join( descriptor )\n",
    "        print(\"Topic %02d: %s\" % ( topic_index+1, str_descriptor ) )\n",
    "    return key_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import NMF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "types = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 01: fuck, shut, asshole, cunt, mother, faggot, fuckin, want, think, dont, nigger, talking, bitches, face, hole, delete, motherfucker, tell, bastard, edit\n",
      "Topic 02: wikipedia, like, just, article, know, people, think, stupid, stop, time, edit, want, make, good, editing, articles, really, blocked, right, edits\n",
      "Topic 03: fucking, cunt, faggot, asshole, life, mother, idiot, retard, hell, bastard, hate, block, kill, stupid, moron, fucker, stop, piece, loser, right\n",
      "Topic 04: suck, dick, cock, faggot, balls, asshole, love, sucks, penis, like, dicks, cunt, lick, head, yeah, likes, dont, pussy, life, nigger\n",
      "Topic 05: talk, page, thanks, user, contribs, pages, edit, redirect, welcome, editing, thank, message, help, discussion, comments, questions, vandalize, comment, leave, hello\n",
      "Topic 06: bitch, stupid, little, asshole, shut, fuckin, nigga, motherfucker, cunt, cock, bastard, whore, pussy, kill, gonna, damn, hell, ugly, balls, dont\n",
      "Topic 07: shit, piece, hell, dont, little, kill, delete, fucker, nigga, stop, real, going, know, fuckin, bastard, head, like, nigger, faggot, gonna\n"
     ]
    }
   ],
   "source": [
    "k = 7\n",
    "\n",
    "nmf = NMF(init=\"nndsvd\", n_components=k, random_state=42) \n",
    "W = nmf.fit_transform(X_train_word) # тематическое представление тектов\n",
    "H = nmf.components_  # темы с вероятностями слов быть по ним\n",
    "\n",
    "key_words = get_all_descriptors(k, H, terms, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "key_words = set([word for theme in key_words for word in theme])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "90"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(key_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "toxic = []\n",
    "severe_toxic = []\n",
    "obscene = ['suck', 'dick', 'cock', 'faggot', 'balls', 'asshole', 'sucks', 'penis', 'dicks', \n",
    "           'cunt', 'lick', 'yeah', 'pussy', 'nigger'] # topic 4\n",
    "threat = []\n",
    "insult = ['fucking', 'cunt', 'faggot', 'asshole', 'mother', 'idiot', 'retard', 'hell', \n",
    "          'bastard', 'hate', 'block', 'kill', 'stupid', 'moron', 'fucker', 'stop', 'piece', 'loser', 'right'] # topic 3\n",
    "identity_hate = ['fuck', 'shut', 'asshole', 'cunt', 'faggot', 'mother', 'fuckin', 'nigger',\n",
    "                 'bitches', 'hole', 'delete', 'motherfucker', 'bastard'] # topic 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_words = pd.DataFrame(columns=key_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "key_dict = {word: [] for word in key_words}\n",
    "for word in key_words:\n",
    "    for message in X_train:\n",
    "        if word in message:\n",
    "            key_dict[word].append(1) \n",
    "        else:\n",
    "            key_dict[word].append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for word in key_dict:\n",
    "    df_words[word] = key_dict[word]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_words_test = pd.DataFrame(columns=key_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "key_dict_test = {word: [] for word in key_words}\n",
    "for word in key_words:\n",
    "    for message in X_test:\n",
    "        if word in message:\n",
    "            key_dict_test[word].append(1) \n",
    "        else:\n",
    "            key_dict_test[word].append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for word in key_dict_test:\n",
    "    df_words_test[word] = key_dict_test[word]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>edits</th>\n",
       "      <th>sucks</th>\n",
       "      <th>delete</th>\n",
       "      <th>love</th>\n",
       "      <th>fuckin</th>\n",
       "      <th>article</th>\n",
       "      <th>fucker</th>\n",
       "      <th>pussy</th>\n",
       "      <th>people</th>\n",
       "      <th>loser</th>\n",
       "      <th>...</th>\n",
       "      <th>comment</th>\n",
       "      <th>pages</th>\n",
       "      <th>life</th>\n",
       "      <th>piece</th>\n",
       "      <th>message</th>\n",
       "      <th>likes</th>\n",
       "      <th>hate</th>\n",
       "      <th>stupid</th>\n",
       "      <th>talking</th>\n",
       "      <th>user</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 90 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   edits  sucks  delete  love  fuckin  article  fucker  pussy  people  loser  \\\n",
       "0      0      0       0     0       0        1       0      0       0      0   \n",
       "1      0      0       1     0       0        1       0      0       0      0   \n",
       "2      0      0       0     0       0        0       0      0       0      0   \n",
       "3      0      0       0     0       0        0       0      0       0      0   \n",
       "4      0      0       1     0       0        1       0      0       0      0   \n",
       "\n",
       "   ...   comment  pages  life  piece  message  likes  hate  stupid  talking  \\\n",
       "0  ...         0      0     0      0        0      0     0       0        0   \n",
       "1  ...         0      0     0      0        0      0     0       0        0   \n",
       "2  ...         0      0     0      0        0      0     0       0        0   \n",
       "3  ...         0      0     0      0        0      0     0       0        0   \n",
       "4  ...         0      0     0      0        0      0     0       0        0   \n",
       "\n",
       "   user  \n",
       "0     0  \n",
       "1     0  \n",
       "2     0  \n",
       "3     0  \n",
       "4     0  \n",
       "\n",
       "[5 rows x 90 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_words_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "char_vectorizer = TfidfVectorizer(\n",
    "    sublinear_tf=True,\n",
    "    strip_accents='unicode',\n",
    "    analyzer='char',\n",
    "    stop_words='english',\n",
    "    ngram_range=(2, 6),\n",
    "    max_features=50000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "char_vectorizer.fit(X)\n",
    "X_train_char = char_vectorizer.transform(X_train)\n",
    "X_test_char = char_vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_features = hstack([X_train_word, X_train_char])\n",
    "test_features = hstack([X_test_word, X_test_char])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Добавляем в вектора наши дополнительные признаки\n",
    "X_train_new = scipy.sparse.hstack([train_features, \n",
    "    scipy.sparse.csr_matrix(df_words[list(key_words)].values)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Добавляем в вектора наши дополнительные признаки\n",
    "X_test_new = scipy.sparse.hstack([test_features, \n",
    "    scipy.sparse.csr_matrix(df_words_test[list(key_words)].values)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<22404x60090 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 15653290 stored elements in COOrdinate format>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<12064x60090 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 8479329 stored elements in COOrdinate format>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "params = {'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000], 'penalty': ['l1', 'l2']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train = df[types]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'LinearSVC' object has no attribute 'predict_proba'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-36-13de81914334>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0msubmission\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/utils/metaestimators.py\u001b[0m in \u001b[0;36m__get__\u001b[0;34m(self, obj, type)\u001b[0m\n\u001b[1;32m    107\u001b[0m                     \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m                     \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdelegate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattribute_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m                     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'LinearSVC' object has no attribute 'predict_proba'"
     ]
    }
   ],
   "source": [
    "# submission = pd.DataFrame.from_dict({'id': df_test['id']})\n",
    "# scores = []\n",
    "\n",
    "# y_train = df[typ]\n",
    "lr = OneVsRestClassifier(LinearSVC(C=0.1))\n",
    "\n",
    "cv_score = np.mean(cross_val_score(lr, train_features, y_train, cv=3, scoring='roc_auc'))\n",
    "# scores.append(cv_score)\n",
    "# print('CV score for class {} is {}'.format(typ, cv_score))\n",
    "\n",
    "lr.fit(train_features, y_train)\n",
    "submission = lr.predict_proba(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id2</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id3</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id4</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id  toxic  severe_toxic  obscene  threat  insult  identity_hate\n",
       "0  id0    0.2           0.0      0.1     0.0     0.1            0.0\n",
       "1  id1    0.1           0.0      0.1     0.0     0.1            0.0\n",
       "2  id2    0.1           0.0      0.1     0.0     0.1            0.0\n",
       "3  id3    0.9           0.0      0.5     0.0     0.6            0.1\n",
       "4  id4    0.1           0.0      0.1     0.0     0.0            0.0"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total CV score is 0.8927121018794498\n"
     ]
    }
   ],
   "source": [
    "print('Total CV score is {}'.format(np.mean(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submission.to_csv('submission2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/socur/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/socur/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/socur/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/socur/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/socur/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/socur/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score='raise',\n",
       "       estimator=LogisticRegression(C=1.0, class_weight='balanced', dual=False,\n",
       "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
       "          multi_class='ovr', n_jobs=1, penalty='l2', random_state=None,\n",
       "          solver='liblinear', tol=0.0001, verbose=0, warm_start=False),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000], 'penalty': ['l1', 'l2']},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='f1', verbose=0)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gcv = GridSearchCV(estimator=lr, param_grid=params, scoring='f1')\n",
    "gcv.fit(X_vec, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/socur/anaconda3/lib/python3.6/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('mean_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/home/socur/anaconda3/lib/python3.6/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('split0_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/home/socur/anaconda3/lib/python3.6/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('split1_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/home/socur/anaconda3/lib/python3.6/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('split2_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/home/socur/anaconda3/lib/python3.6/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('std_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>param_C</th>\n",
       "      <th>param_penalty</th>\n",
       "      <th>params</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>3.694677</td>\n",
       "      <td>0.005972</td>\n",
       "      <td>0.879253</td>\n",
       "      <td>0.997736</td>\n",
       "      <td>1000</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'C': 1000, 'penalty': 'l2'}</td>\n",
       "      <td>1</td>\n",
       "      <td>0.877981</td>\n",
       "      <td>0.997358</td>\n",
       "      <td>0.879316</td>\n",
       "      <td>0.997682</td>\n",
       "      <td>0.880461</td>\n",
       "      <td>0.998167</td>\n",
       "      <td>0.071274</td>\n",
       "      <td>0.000085</td>\n",
       "      <td>0.001014</td>\n",
       "      <td>0.000332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2.319563</td>\n",
       "      <td>0.006220</td>\n",
       "      <td>0.879115</td>\n",
       "      <td>0.997573</td>\n",
       "      <td>100</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'C': 100, 'penalty': 'l2'}</td>\n",
       "      <td>2</td>\n",
       "      <td>0.877860</td>\n",
       "      <td>0.997142</td>\n",
       "      <td>0.880111</td>\n",
       "      <td>0.997574</td>\n",
       "      <td>0.879375</td>\n",
       "      <td>0.998005</td>\n",
       "      <td>0.295282</td>\n",
       "      <td>0.000301</td>\n",
       "      <td>0.000937</td>\n",
       "      <td>0.000352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.252314</td>\n",
       "      <td>0.006068</td>\n",
       "      <td>0.876607</td>\n",
       "      <td>0.996169</td>\n",
       "      <td>10</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'C': 10, 'penalty': 'l2'}</td>\n",
       "      <td>3</td>\n",
       "      <td>0.875108</td>\n",
       "      <td>0.995629</td>\n",
       "      <td>0.877163</td>\n",
       "      <td>0.996062</td>\n",
       "      <td>0.877549</td>\n",
       "      <td>0.996815</td>\n",
       "      <td>0.018323</td>\n",
       "      <td>0.000138</td>\n",
       "      <td>0.001071</td>\n",
       "      <td>0.000490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.743346</td>\n",
       "      <td>0.009271</td>\n",
       "      <td>0.870900</td>\n",
       "      <td>0.997700</td>\n",
       "      <td>100</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'C': 100, 'penalty': 'l1'}</td>\n",
       "      <td>4</td>\n",
       "      <td>0.870715</td>\n",
       "      <td>0.997304</td>\n",
       "      <td>0.871287</td>\n",
       "      <td>0.997682</td>\n",
       "      <td>0.870697</td>\n",
       "      <td>0.998113</td>\n",
       "      <td>0.148324</td>\n",
       "      <td>0.002377</td>\n",
       "      <td>0.000274</td>\n",
       "      <td>0.000330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1.706011</td>\n",
       "      <td>0.008081</td>\n",
       "      <td>0.870135</td>\n",
       "      <td>0.997718</td>\n",
       "      <td>1000</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'C': 1000, 'penalty': 'l1'}</td>\n",
       "      <td>5</td>\n",
       "      <td>0.866324</td>\n",
       "      <td>0.997358</td>\n",
       "      <td>0.873622</td>\n",
       "      <td>0.997628</td>\n",
       "      <td>0.870460</td>\n",
       "      <td>0.998167</td>\n",
       "      <td>0.132558</td>\n",
       "      <td>0.001534</td>\n",
       "      <td>0.002988</td>\n",
       "      <td>0.000336</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  mean_score_time  mean_test_score  mean_train_score param_C  \\\n",
       "13       3.694677         0.005972         0.879253          0.997736    1000   \n",
       "11       2.319563         0.006220         0.879115          0.997573     100   \n",
       "9        1.252314         0.006068         0.876607          0.996169      10   \n",
       "10       1.743346         0.009271         0.870900          0.997700     100   \n",
       "12       1.706011         0.008081         0.870135          0.997718    1000   \n",
       "\n",
       "   param_penalty                        params  rank_test_score  \\\n",
       "13            l2  {'C': 1000, 'penalty': 'l2'}                1   \n",
       "11            l2   {'C': 100, 'penalty': 'l2'}                2   \n",
       "9             l2    {'C': 10, 'penalty': 'l2'}                3   \n",
       "10            l1   {'C': 100, 'penalty': 'l1'}                4   \n",
       "12            l1  {'C': 1000, 'penalty': 'l1'}                5   \n",
       "\n",
       "    split0_test_score  split0_train_score  split1_test_score  \\\n",
       "13           0.877981            0.997358           0.879316   \n",
       "11           0.877860            0.997142           0.880111   \n",
       "9            0.875108            0.995629           0.877163   \n",
       "10           0.870715            0.997304           0.871287   \n",
       "12           0.866324            0.997358           0.873622   \n",
       "\n",
       "    split1_train_score  split2_test_score  split2_train_score  std_fit_time  \\\n",
       "13            0.997682           0.880461            0.998167      0.071274   \n",
       "11            0.997574           0.879375            0.998005      0.295282   \n",
       "9             0.996062           0.877549            0.996815      0.018323   \n",
       "10            0.997682           0.870697            0.998113      0.148324   \n",
       "12            0.997628           0.870460            0.998167      0.132558   \n",
       "\n",
       "    std_score_time  std_test_score  std_train_score  \n",
       "13        0.000085        0.001014         0.000332  \n",
       "11        0.000301        0.000937         0.000352  \n",
       "9         0.000138        0.001071         0.000490  \n",
       "10        0.002377        0.000274         0.000330  \n",
       "12        0.001534        0.002988         0.000336  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(gcv.cv_results_).sort_values(by='rank_test_score').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
